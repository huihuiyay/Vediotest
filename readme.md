# ğŸ“Š **metrics/README.md â€” è§†é¢‘ç”Ÿæˆ/ç¼–è¾‘è´¨é‡è¯„æµ‹æŒ‡å—**

æ•´åˆ 5 å¥—å¸¸ç”¨è¯„æµ‹å·¥å…·ï¼š  
1) **VBench**ï¼ˆğŸ¯ å•è§†é¢‘è´¨é‡ç»´åº¦ï¼‰  
2) **VE-Bench QA**ï¼ˆğŸ§  æ–‡æœ¬-è§†é¢‘ä¸€è‡´æ€§ï¼Œè¾“å…¥â†’è¾“å‡ºï¼‰  
3) **ArcFace**ï¼ˆğŸ§‘â€ğŸ¤â€ğŸ§‘ ç”Ÿæˆå‰åäººè„¸ç›¸ä¼¼åº¦ï¼‰  
4) **OpenFace è‡ªç„¶åº¦**ï¼ˆğŸ­ åŸºäº AU çš„è¡¨æƒ…è‡ªç„¶åº¦ï¼‰  
5) **SyncNet / Wav2Lip**ï¼ˆğŸ‘„ å£å‹ä¸€è‡´æ€§ï¼šLSE-D / LSE-Cï¼‰

[[_TOC_]]

---

## 1ï¸âƒ£ **ç¯å¢ƒä¸€ï¼ˆé€‚ç”¨è¯„æµ‹ 1~3ï¼‰** âš™ï¸

```bash
cd metrics/Vbench
conda env create -f vbench312.yaml
conda activate vbench312
```


### ğŸ¯ 1. VBenchï¼šå•è§†é¢‘è´¨é‡ç»´åº¦è¯„æµ‹

æ”¯æŒç»´åº¦ï¼š
subject_consistency, background_consistency, motion_smoothness, dynamic_degree, aesthetic_quality, imaging_quality

```bash
CUDA_VISIBLE_DEVICES=0 \
python evaluate.py \
  --dimension $DIMENSION \
  --videos_path /path/to/folder_or_video \
  --mode custom_input \
  --output_path ~/vbench_out
```


ğŸ’¡ --videos_path å¯æŒ‡å‘å•ä¸ªè§†é¢‘æˆ–åŒ…å«å¤šä¸ªè§†é¢‘çš„æ–‡ä»¶å¤¹ï¼›ç»“æœè¾“å‡ºåœ¨ --output_pathã€‚


### ğŸ§  2. VE-Bench QAï¼šè¾“å…¥â†’ç”Ÿæˆè§†é¢‘è´¨é‡è¯„æµ‹ï¼ˆå¯åŠ æç¤ºè¯ï¼‰


```bash
python - <<'PY'
from vebench import VEBenchModel
e = VEBenchModel()
print(e.evaluate(
  "A girl stands upright, confident gaze, slight smile, hands on hips, poised and assertive.",
  "/media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/input.mp4",
  "/media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/output_00.mp4"
))
PY
```


### ğŸ§‘â€ğŸ¤â€ğŸ§‘ 3. ArcFaceï¼šç”Ÿæˆå‰åè§†é¢‘é¢éƒ¨ç›¸ä¼¼åº¦è¯„ä¼°
```bash
python vid2vid_arcface_compare.py \
  --src /media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/input.mp4 \
  --gen /media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/output_01.mp4 \
  --num-frames 64 \
  --save-csv ./idsim_results.csv
```

## **2ï¸âƒ£ ç¯å¢ƒäºŒï¼ˆé€‚ç”¨è¯„æµ‹ 4ï¼‰ ğŸ§ª**

```bash
conda env create -f faceeval.yaml
conda activate faceeval
```


### ğŸ­ 4. é¢éƒ¨è¡¨æƒ…è‡ªç„¶åº¦è¯„ä¼°ï¼ˆOpenFace AU â†’ è¯„åˆ†è„šæœ¬ï¼‰

éœ€å…ˆç”¨ OpenFace å¯¹æºè§†é¢‘ä¸ç”Ÿæˆè§†é¢‘åˆ†åˆ«æå– AUï¼Œå†è°ƒç”¨è¯„ä¼°è„šæœ¬ã€‚
å¦‚é‡ä¾èµ–å†²çªï¼Œå¯å…ˆè®¾ç½®è¿è¡Œåº“è·¯å¾„ï¼šexport LD_LIBRARY_PATH="$HOME/.local/lib:${LD_LIBRARY_PATH}"

**4.1 æå– AU**
    
- æºè§†é¢‘ï¼ˆSRCï¼‰
```bash
"metrics/Vbench/OpenFace/build/bin/FeatureExtraction" \
  -f "/media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/input.mp4" \
  -aus -2Dfp \
  -out_dir "/media/yuzihui/17A26BDB4251F93F/project/multimodalinteract/metrics/Vbench/OpenFace/openface_out/src"
```
- ç”Ÿæˆè§†é¢‘ï¼ˆGENï¼‰
```bash
"metrics/Vbench/OpenFace/build/bin/FeatureExtraction" \
  -f "/media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/output_00.mp4" \
  -aus -2Dfp \
  -out_dir "/media/yuzihui/17A26BDB4251F93F/project/multimodalinteract/metrics/Vbench/OpenFace/openface_out/gen"
```

**4.2 è‡ªç„¶åº¦è¯„æµ‹**

```bash
python eval_openface_naturalness.py \
  --src_csv  /media/yuzihui/17A26BDB4251F93F/project/multimodalinteract/metrics/Vbench/OpenFace/openface_out/src/input.csv \
  --gen_csv  /media/yuzihui/17A26BDB4251F93F/project/multimodalinteract/metrics/Vbench/OpenFace/openface_out/gen/output_00.csv \
  --src_video /media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/input.mp4 \
  --gen_video /media/yuzihui/17A26BDB4251F93F/project/VBench/testvideo/output_00.mp4 \
  --prompt "A girl stands upright, confident gaze, slight smile, hands on hips, poised and assertive." \
  --num_frames 256 \
  --device auto \
  --save_dir ./openface_eval_out
```


ğŸ“‚ è¾“å‡ºï¼ˆå›¾è¡¨/CSVï¼‰å°†ä¿å­˜è‡³ --save_dirã€‚
â— è·¯å¾„å¤§å°å†™æ•æ„Ÿï¼šè¯·ç¡®ä¿ metrics/Vbench ç­‰ç›®å½•ä¸ä»“åº“ä¸€è‡´ã€‚
 
## **3ï¸âƒ£ ç¯å¢ƒä¸‰ï¼ˆé€‚ç”¨è¯„æµ‹ 5ï¼‰ ğŸµ**

```bash
cd metrics/syncnet_python
conda env create -f lse_eval.yaml
conda activate lse_eval
```


### ğŸ‘„ 5. å£å‹ä¸€è‡´æ€§è¯„ä¼°ï¼ˆWav2Lip / SyncNetï¼šLSE-D & LSE-Cï¼‰

```bash 
sh calculate_scores_real_videos.sh /path/to/video/data/root
```

ğŸ“ ä¼ å…¥çš„æ˜¯æ•°æ®æ ¹ç›®å½•ï¼ˆåŒ…å«å¾…è¯„æµ‹è§†é¢‘çš„æ–‡ä»¶å¤¹ï¼‰ï¼Œè€Œä¸æ˜¯å•ä¸ªè§†é¢‘æ–‡ä»¶ã€‚
ğŸ’¾ LSE è¯„ä¼°ç»“æœï¼ˆæ—¥å¿—/CSVï¼‰æŒ‰è„šæœ¬çº¦å®šè·¯å¾„è¾“å‡ºã€‚


ğŸ“ å»ºè®®çš„ç›®å½•ç»“æ„
```
project/
  VBench/testvideo/
    input.mp4
    output_00.mp4
    output_01.mp4
  vbench_out/                   # VBench è¾“å‡º
  openface_eval_out/            # OpenFace è¯„æµ‹è¾“å‡º
  metrics/
    Vbench/
      OpenFace/
        build/bin/FeatureExtraction
        openface_out/
          src/input.csv
          gen/output_00.csv
    syncnet_python/
      lse_eval.yaml
```

### ğŸ’¡ Tips

GPU æŒ‡å®šï¼šCUDA_VISIBLE_DEVICES=0ï¼ˆæˆ–é€—å·åˆ†éš”å¤šä¸ªï¼‰

Conda æ¿€æ´»ï¼šä»¥å„ YAML çš„ name ä¸ºå‡†ï¼Œæ¯”å¦‚ conda activate vbench312

è·¯å¾„è§„èŒƒï¼šå»ºè®®ç»Ÿä¸€ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œæˆ–åœ¨é¡¹ç›®å†…ä¿æŒç¨³å®šçš„ç›¸å¯¹ç›®å½•

### ğŸ“ è®¸å¯ä¸è‡´è°¢

ä¸Šè¿°è¯„æµ‹è„šæœ¬ä¸æ–¹æ³•æºäºå„å¼€æºé¡¹ç›®ï¼ˆVBenchã€VE-Benchã€ArcFaceã€OpenFaceã€Wav2Lip/SyncNetï¼‰ã€‚

è¯·éµå¾ªå„è‡ª License ä½¿ç”¨ä¸å¼•ç”¨ã€‚
